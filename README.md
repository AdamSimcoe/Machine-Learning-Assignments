# Machine-Learning-Assignments

This README serves as a summary of the numerous machine-learning related assignments I have been able to work on during my time at George Brown College. Within this repository you can find both the associated code and video presentations on each of the following subjects:

## Kaggle Competition for Predicting Housing Prices

### Description
This assignment focused on participating in Kaggle's housing price prediction competition. The goal of it was to analyze real-world housing data and help predict the final sale prices using regression model. Both Linear Regression and Random Forest techniques were implemented and their results were compared. This project helped deepen my understanding of preprocessing numerical and categorical features, handling missing data, and evaluating regression model performance using RMSE.

### Video Presentation
https://www.youtube.com/watch?v=_m2vubKO7vs

## Working with the Fashion MNIST dataset

### Description
This assignment used the fashion MNIST dataset, which contains grayscale images of clothing items categorized into 10 different potential labels (such as shirts, shoes, etc.). A Sequential Model was trained on it using Dense layers, flattening, ReLU activations, and softmax output. The labels were converted using one-hot encoding and the model was compiled using categorical crossentropy. This project helped reinforce my fundamental concepts of image classification, data normalization, and training using batch processing over multiple epochs.

### Video Presentation
https://www.youtube.com/watch?v=WNfnyHkOagw

## Working with the Iris Dataset

### Description
This assignment explored multiclass classification using the Iris dataset, which includes measurements of different iris flower species. A neural network was trained to classify among the three species using Dense layers and ReLU activation. Various optimizers, batch sizes, number of epochs, and hidden units were experimented with to observe their overall impact on the model's performance. This project focused on deepening my understanding of model tuning, training-validation splits, and model perfomance evaluation using accuracy and loss metrics.

### Video Presentation
https://www.youtube.com/watch?v=gFV3zdO-ZeA

## Learning to use Convolution 

### Description
This assignment was divided into two major parts. First, it visualized how 2D convolution using kernels can enhance or extract features from images (such as edges and lines). Secondly, a Convolutional Neural Network was built using Conv2D, MaxPooling2D, and Flatten layers to classify image data. This project solifided my understanding of concepts such as feature extraction, convolution operations, and the overall importance of spatial hierarchy in image-based learning.

### Video Presentation
https://www.youtube.com/watch?v=rzzwe-5M3YU

## Reducing the Overfitting Problem

### Description
This assignment acted as a culmination of my work regarding Machine Learning. It used the CIFAR-10 dataset to implement advanced techniques aimed at reducing overfitting in deep learning models. Starting with a base CNN, various improvements were added in increments, including Dropout layers, L2 Regularization, Batch Normalization, and ImageDataGenerator for data augmentation. The final model combined these strategies to help improve our model's generalization and achieve a high accuracy. This project emphasized the key concepts in regularization, hyperparameter tuning, and using early stopping and learning rate schedules during training. 

### Video Presentation
https://www.youtube.com/watch?v=bwSiwBuKtXg